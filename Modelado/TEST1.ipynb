{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1jz6qS5vThs"
      },
      "source": [
        "# Analisis de Sentimientos Foros Moodle Deep Learning Modelo 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importar las librerias necesarias"
      ],
      "metadata": {
        "id": "Q7tOpXGiajnn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUbKjkYutiOV",
        "outputId": "a308d8aa-f051-4954-ef80-a9720a230d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#!python -m spacy download es_core_news_sm\n",
        "#!pip install fasttext\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import csv\n",
        "import warnings\n",
        "import lxml.html.clean\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "from re import sub\n",
        "import multiprocessing\n",
        "from textblob import TextBlob\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 999)\n",
        "import nltk\n",
        "import nltk.data\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk import FreqDist\n",
        "from bs4 import BeautifulSoup\n",
        "import re, string, unicodedata\n",
        "import spacy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import collections\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import logging\n",
        "from gensim.models import word2vec\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from collections import defaultdict\n",
        "from keras.layers.convolutional import Convolution1D\n",
        "from keras import backend as K\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords') \n",
        "stop_words =stopwords.words('spanish')\n",
        "#nlp = spacy.load('es_core_news_sm')\n",
        "stemmer = SnowballStemmer(\"spanish\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar Conjunto de Datos Consolidado"
      ],
      "metadata": {
        "id": "8ntGmAeMauhX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNhhgQCmuF6M",
        "outputId": "ec049a6e-e64f-41f2-a5f9-cf6babf14468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/',force_remount=True)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "df= pd.read_csv('/content/gdrive/My Drive/TFM_Analisis_Sentimientos/Corpus/dataset_balanced.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre procesamiento"
      ],
      "metadata": {
        "id": "k2tFLXlXax2_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWmPj9itvkcN"
      },
      "outputs": [],
      "source": [
        "#Funciones para limpiar el texto\n",
        "#!pip install spacy\n",
        "#!python -m spacy download es_core_news_sm\n",
        "\n",
        "stop_words.extend(['si', 'tambien', 'asi', 'debe', 'tener','cada','ademas','parte','ser','ma','mismo','mas'])  \n",
        "\n",
        "def processText(raw_text, remove_stopwords=True, stemming=False, split_text=False):\n",
        "\n",
        "    if remove_stopwords: # Eliminar palabras vacias\n",
        "        stops = set(stopwords.words(\"spanish\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "          \n",
        "    if split_text==True:  # split text\n",
        "        return (words)    \n",
        "    \n",
        "    return( \" \".join(words)) \n",
        "\n",
        "\n",
        "def sentiment_num(sentiment):\n",
        "  if sentiment == 'POSITIVO':\n",
        "    return 1\n",
        "  elif sentiment == 'NEGATIVO':\n",
        "    return -1\n",
        "  elif sentiment == 'NEUTRAL':\n",
        "    return 0  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "h7bUzB4qyGJM",
        "outputId": "30e6d09c-d250-4248-a881-0487c53ba607"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7b0182dc-18fc-4436-a0df-def9104035d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>curso muy interesante en cuanto a contenido y en cuanto a desarrollo personal</td>\n",
              "      <td>POSITIVO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>el mejor saludos desde panama</td>\n",
              "      <td>POSITIVO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>es estupenda la manera en que te ensenan muy didactico y claro le doy un</td>\n",
              "      <td>POSITIVO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>me ha parecido un curso fantastico breve didactico y muy bien preparado¡felicidadesfrancisco eugenio</td>\n",
              "      <td>POSITIVO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>primera replica bueno creo que falta organizar la ideas pero al menos se miro el video de forma rapida en saltos como de cierta forma se responde con alguna ideas bastantes cambios que presenta ofrece distintas fases cambiante e incluso alterable teorias cientificas flexibles que se permiten adaptar etc lo que no comprendo son las siguientes frases investigaciones beneficiosas y lucrativas para el crecimiento de estas ciencias ciencia complejo ingenioso conocimiento para pasar de algo antiguo a algo innovador la ciencia trata de preguntar constantemente el porque de las cosas completamente redimidas esto es inedito en seguir buscando y este siga siendo persistente considero que ademas no se revisa lo que pide la pregunta que al plano de relatar lo presenta el conferencista tambien cosiste en relatar la experiencia personal de la cual no ha y nada en esta primera replica</td>\n",
              "      <td>POSITIVO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>es muy claro que la pelicula es una recopilacion de hechos historicos en los cuales representan varios temas tratados en clase como la desviacion en la que un lider cambia su proposito o los medios manipulan la informacion para conveniencia se establece que la institucion es el estado que gobierna con unas leyes a conveniencia y lleva a un fanatismos con simbolizado con una imitacion por la esvastica utilizada por hitler por otro lado es un llamado a la revolucion necesaria asi conocida desde la revolucion francesa que se ha visto reflejada en muchas ocasiones con el fin de proteger una vez mas al pueblo oprimido y atacar el sistema que beneficia a unos cuantos en un punto de vista personal senti que esa pelicula solo cambio el contexto historico y llevo a las pantallas para demostrar el lema muy conocido el exceso del poder corrompe ya que aunque la idea de revolucion es necesaria no debe manejarse de esa forma</td>\n",
              "      <td>POSITIVO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>excelente curso muy enriquecedor</td>\n",
              "      <td>POSITIVO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>excelente curso todos los aplausos y felicitaciones para el docente excelente y explicito el material que nos brindo muy completo la verdad quedo mas que feliz y agradecida con el docente y la universidad</td>\n",
              "      <td>POSITIVO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b0182dc-18fc-4436-a0df-def9104035d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b0182dc-18fc-4436-a0df-def9104035d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b0182dc-18fc-4436-a0df-def9104035d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             text  \\\n",
              "0  curso muy interesante en cuanto a contenido y en cuanto a desarrollo personal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "1  el mejor saludos desde panama                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
              "2  es estupenda la manera en que te ensenan muy didactico y claro le doy un                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
              "3  me ha parecido un curso fantastico breve didactico y muy bien preparado¡felicidadesfrancisco eugenio                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
              "4  primera replica bueno creo que falta organizar la ideas pero al menos se miro el video de forma rapida en saltos como de cierta forma se responde con alguna ideas bastantes cambios que presenta ofrece distintas fases cambiante e incluso alterable teorias cientificas flexibles que se permiten adaptar etc lo que no comprendo son las siguientes frases investigaciones beneficiosas y lucrativas para el crecimiento de estas ciencias ciencia complejo ingenioso conocimiento para pasar de algo antiguo a algo innovador la ciencia trata de preguntar constantemente el porque de las cosas completamente redimidas esto es inedito en seguir buscando y este siga siendo persistente considero que ademas no se revisa lo que pide la pregunta que al plano de relatar lo presenta el conferencista tambien cosiste en relatar la experiencia personal de la cual no ha y nada en esta primera replica                                               \n",
              "5  es muy claro que la pelicula es una recopilacion de hechos historicos en los cuales representan varios temas tratados en clase como la desviacion en la que un lider cambia su proposito o los medios manipulan la informacion para conveniencia se establece que la institucion es el estado que gobierna con unas leyes a conveniencia y lleva a un fanatismos con simbolizado con una imitacion por la esvastica utilizada por hitler por otro lado es un llamado a la revolucion necesaria asi conocida desde la revolucion francesa que se ha visto reflejada en muchas ocasiones con el fin de proteger una vez mas al pueblo oprimido y atacar el sistema que beneficia a unos cuantos en un punto de vista personal senti que esa pelicula solo cambio el contexto historico y llevo a las pantallas para demostrar el lema muy conocido el exceso del poder corrompe ya que aunque la idea de revolucion es necesaria no debe manejarse de esa forma    \n",
              "6  excelente curso muy enriquecedor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "7  excelente curso todos los aplausos y felicitaciones para el docente excelente y explicito el material que nos brindo muy completo la verdad quedo mas que feliz y agradecida con el docente y la universidad                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "\n",
              "  sentiment  \n",
              "0  POSITIVO  \n",
              "1  POSITIVO  \n",
              "2  POSITIVO  \n",
              "3  POSITIVO  \n",
              "4  POSITIVO  \n",
              "5  POSITIVO  \n",
              "6  POSITIVO  \n",
              "7  POSITIVO  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df.head(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBv3EeAIx8bV"
      },
      "outputs": [],
      "source": [
        "df['sentiment'] = df['sentiment'].apply(sentiment_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dividir en datos de entrenamiento y test"
      ],
      "metadata": {
        "id": "44Ehp0aLccyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], \\\n",
        "                                                    test_size=0.1, random_state=0)"
      ],
      "metadata": {
        "id": "PDZI1X5i7D_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vqssj3ev9Jy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_cleaned = []\n",
        "X_test_cleaned = []\n",
        "\n",
        "for d in X_train:\n",
        "    X_train_cleaned.append(processText(d))\n",
        "\n",
        "for d in X_test:\n",
        "    X_test_cleaned.append(processText(d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Er0t80HI-zqe",
        "outputId": "99faab6c-3876-44fe-8e86-7b212e15fac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-8ee9c8584ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_train_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-cd87001f5d59>\u001b[0m in \u001b[0;36mprocessText\u001b[0;34m(raw_text, remove_stopwords, stemming, split_text)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Eliminar palabras vacias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mstops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spanish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msplit_text\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# split text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'words' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split review text into parsed sentences uisng NLTK's punkt tokenizer\n",
        "# nltk.download()\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')\n",
        "\n",
        "def parseSent(review, tokenizer, remove_stopwords=False):\n",
        "    '''\n",
        "    Parse text into sentences\n",
        "    '''\n",
        "    raw_sentences = tokenizer.tokenize(review.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append(cleanText(raw_sentence, remove_stopwords, split_text=True))\n",
        "    return sentences\n",
        "\n",
        "\n",
        "# Parse each review in the training set into sentences\n",
        "sentences = []\n",
        "for review in X_train_cleaned:\n",
        "    sentences += parseSent(review, tokenizer)\n",
        "    \n",
        "print('%d parsed sentence in the training set\\n'  %len(sentences))\n",
        "print('Show a parsed sentence in the training set : \\n',  sentences[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w94ogpl77D74",
        "outputId": "bc514ea5-d1d2-42d3-cccc-4fd07d2ce425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8694 parsed sentence in the training set\n",
            "\n",
            "Show a parsed sentence in the training set : \n",
            " ['cual', 'de', 'todas', 'las', 'herramientas', 'mencionadas', 'fue', 'la', 'que', 'mas', 'le', 'llamo', 'la', 'atencionrespuestala', 'herramienta', 'que', 'mas', 'me', 'llamo', 'la', 'atencion', 'fue', 'el', 'biofeedback', 'debido', 'a', 'que', 'esta', 'permite', 'que', 'el', 'paciente', 'con', 'ayuda', 'y', 'supervision', 'del', 'terapeuta', 'es', 'consciente', 'de', 'algunos', 'procesos', 'fisiologicos', 'de', 'los', 'cuales', 'normalmente', 'no', 'tiene', 'en', 'cuenta', 'para', 'indentificarlos', 'y', 'posteriormente', 'controlarlos', 'se', 'incia', 'colocando', 'sensores', 'al', 'paciente', 'los', 'cuales', 'no', 'son', 'invasivos', 'y', 'permite', 'recoger', 'una', 'senal', 'que', 'se', 'presentara', 'en', 'la', 'pantalla', 'de', 'un', 'computador', 'para', 'que', 'el', 'paciente', 'evidencie', 'aquellas', 'alteraciones', 'dependiendo', 'su', 'caso', 'y', 'por', 'medio', 'del', 'psicologo', 'las', 'mejores', 'alternativas', 'de', 'solucion', 'para', 'tratarlo', 'mientras', 'el', 'paciente', 'es', 'testigo', 'de', 'su', 'problema', 'ademas', 'esto', 'le', 'permite', 'utilizar', 'otro', 'ejes', 'terapeuticos', 'como', 'la', 'computacion', 'persuasiva', 'epecificamente', 'con', 'problemas', 'en', 'ninos', 'utilizando', 'tambien', 'el', 'condicionamiento', 'cuales', 'son', 'las', 'ventajas', 'y', 'desventajas', 'de', 'los', 'nuevos', 'avances', 'tecnologicos', 'en', 'la', 'psicologiarespuesta', 'la', 'llegada', 'de', 'la', 'tecnologia', 'ha', 'implicado', 'una', 'revolucion', 'en', 'la', 'psicologia', 'puesto', 'que', 'permite', 'el', 'desarrollo', 'y', 'acceso', 'de', 'nuevas', 'estrategias', 'terapeuticas', 'haciendo', 'que', 'estas', 'tengan', 'un', 'soporte', 'y', 'validez', 'mas', 'exacto', 'con', 'programas', 'modernos', 'especificos', 'para', 'la', 'medicion', 'de', 'diferentes', 'sintomas', 'que', 'aunque', 'puedan', 'mantener', 'un', 'porciento', 'de', 'error', 'demuestran', 'mas', 'fiabilidad', 'que', 'aquellas', 'que', 'no', 'implican', 'aparatos', 'tecnologicos', 'tambien', 'ha', 'facilitado', 'la', 'terapia', 'online', 'en', 'tiempos', 'como', 'este', 'donde', 'la', 'salud', 'mental', 'se', 'deteriora', 'y', 'es', 'mas', 'complicado', 'mantener', 'acudir', 'a', 'terapias', 'psicologicas', 'incito', 'la', 'implemenctacion', 'de', 'recursos', 'que', 'contribuyen', 'a', 'la', 'mejora', 'del', 'tratamiento', 'psicologico', 'y', 'le', 'establece', 'al', 'terapeuta', 'un', 'campo', 'de', 'vision', 'mas', 'amplio', 'desde', 'la', 'psicologia', 'con', 'relacion', 'de', 'otras', 'ramas', 'como', 'la', 'neurologia', 'o', 'fisiologia', 'despues', 'de', 'distinguir', 'las', 'ventajas', 'que', 'traen', 'estos', 'avances', 'tambien', 'debemos', 'ser', 'conscientes', 'de', 'aquellas', 'desventajas', 'o', 'falencias', 'que', 'puede', 'traer', 'consgio', 'este', 'tipo', 'de', 'desarrollo', 'partiendo', 'de', 'que', 'estos', 'mismos', 'tratamientos', 'pueden', 'limitarse', 'a', 'resultados', 'determinados', 'todos', 'los', 'procesos', 'no', 'son', 'asequibles', 'para', 'todas', 'las', 'personas', 'y', 'representa', 'una', 'disminucion', 'de', 'la', 'interaccion', 'psicologopaciente', 'que', 'habilidades', 'debemos', 'tener', 'los', 'psicologos', 'oara', 'aprovechar', 'las', 'nuevas', 'tecnologiasrespuesta', 'estas', 'tecnologias', 'proporcionan', 'gran', 'ayuda', 'a', 'los', 'tratamientos', 'del', 'psicologo', 'pero', 'si', 'este', 'no', 'cuenta', 'con', 'una', 'buena', 'formacion', 'con', 'base', 'a', 'sus', 'conocimientos', 'tanto', 'de', 'la', 'psicologia', 'en', 'si', 'como', 'del', 'uso', 'de', 'estas', 'herramientas', 'no', 'lo', 'va', 'a', 'manejar', 'de', 'manera', 'optima', 'e', 'incluso', 'podria', 'causarle', 'dano', 'al', 'paciente', 'no', 'puede', 'depender', 'exclusivamente', 'de', 'estos', 'equipos', 'ya', 'que', 'es', 'de', 'vital', 'importancia', 'su', 'interpretacion', 'para', 'formular', 'buenos', 'procesos', 'terapeuticos', 'tambien', 'debe', 'asumir', 'con', 'compromiso', 'y', 'empatia', 'las', 'alternativas', 'de', 'solucion', 'que', 'maneja', 'pensando', 'siempre', 'en', 'los', 'mas', 'adecuados', 'para', 'el', 'paciente']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrenar al modelo Word2Vec"
      ],
      "metadata": {
        "id": "zOleBz11cmaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 300  #embedding dimension                     \n",
        "min_word_count = 10                \n",
        "num_workers = 4       \n",
        "context = 10                                                                                          \n",
        "downsampling = 1e-3 \n",
        "\n",
        "print(\"Training Word2Vec model ...\\n\")\n",
        "w2v = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count,\\\n",
        "                 window = context, sample = downsampling)\n",
        "w2v.init_sims(replace=True)\n",
        "w2v.save(\"w2v_300features_10minwordcounts_10context\") #save trained word2vec model\n",
        "\n",
        "print(\"Number of words in the vocabulary list : %d \\n\" %len(w2v.wv.index2word)) #4016 \n",
        "print(\"Show first 10 words in the vocalbulary list  vocabulary list: \\n\", w2v.wv.index2word[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsCRxUUo7D5B",
        "outputId": "cba78d13-c1f5-4af1-cacd-27399adcd8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Word2Vec model ...\n",
            "\n",
            "Number of words in the vocabulary list : 5285 \n",
            "\n",
            "Show first 10 words in the vocalbulary list  vocabulary list: \n",
            " ['de', 'la', 'que', 'y', 'el', 'en', 'a', 'los', 'se', 'es']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfrom the training data into feature vectors\n",
        "\n",
        "def makeFeatureVec(review, model, num_features):\n",
        "    '''\n",
        "    Transform a review to a feature vector by averaging feature vectors of words \n",
        "    appeared in that review and in the volcabulary list created\n",
        "    '''\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    nwords = 0.\n",
        "    index2word_set = set(model.wv.index2word) #index2word is the volcabulary list of the Word2Vec model\n",
        "    isZeroVec = True\n",
        "    for word in review:\n",
        "        if word in index2word_set: \n",
        "            nwords = nwords + 1.\n",
        "            featureVec = np.add(featureVec, model[word])\n",
        "            isZeroVec = False\n",
        "    if isZeroVec == False:\n",
        "        featureVec = np.divide(featureVec, nwords)\n",
        "    return featureVec\n",
        "\n",
        "\n",
        "def getAvgFeatureVecs(reviews, model, num_features):\n",
        "    '''\n",
        "    Transform all reviews to feature vectors using makeFeatureVec()\n",
        "    '''\n",
        "    counter = 0\n",
        "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
        "    for review in reviews:\n",
        "        reviewFeatureVecs[counter] = makeFeatureVec(review, model,num_features)\n",
        "        counter = counter + 1\n",
        "    return reviewFeatureVecs"
      ],
      "metadata": {
        "id": "s5d_Cbak7D16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature vectors for training set\n",
        "X_train_cleaned = []\n",
        "for review in X_train:\n",
        "    X_train_cleaned.append(cleanText(review, remove_stopwords=True, split_text=True))\n",
        "trainVector = getAvgFeatureVecs(X_train_cleaned, w2v, num_features)\n",
        "print(\"Training set : %d feature vectors with %d dimensions\" %trainVector.shape)\n",
        "\n",
        "\n",
        "# Get feature vectors for validation set\n",
        "X_test_cleaned = []\n",
        "for review in X_test:\n",
        "    X_test_cleaned.append(cleanText(review, remove_stopwords=True, split_text=True))\n",
        "testVector = getAvgFeatureVecs(X_test_cleaned, w2v, num_features)\n",
        "print(\"Validation set : %d feature vectors with %d dimensions\" %testVector.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3OXb4Hp7Dyl",
        "outputId": "37e65a2b-00ef-48a4-94be-e55d977835bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set : 8694 feature vectors with 300 dimensions\n",
            "Validation set : 966 feature vectors with 300 dimensions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained Word2Vec model\n",
        "w2v = Word2Vec.load(\"w2v_300features_10minwordcounts_10context\")\n",
        "\n",
        "\n",
        "# Get Word2Vec embedding matrix\n",
        "embedding_matrix = w2v.wv.syn0  # embedding matrix, type = numpy.ndarray \n",
        "print(\"Shape of embedding matrix : \", embedding_matrix.shape) #(4016, 300) = (volcabulary size, embedding dimension)\n",
        "# w2v.wv.syn0[0] #feature vector of the first word in the volcabulary list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XPNJVQv7DvG",
        "outputId": "d2d2e1bc-7128-41eb-d80f-0fc64e2e41ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embedding matrix :  (5285, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v.most_similar(positive=['excelente'], topn = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yr1lZpjO3y1",
        "outputId": "6bde3be6-5646-4252-f59a-df7dc96dee1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('finanzas', 0.9381696581840515),\n",
              " ('programacion', 0.9275283813476562),\n",
              " ('completo', 0.926627516746521),\n",
              " ('r', 0.9260179400444031),\n",
              " ('recomendado', 0.917519211769104),\n",
              " ('practico', 0.9111957550048828),\n",
              " ('introduccion', 0.894296407699585),\n",
              " ('basico', 0.889096736907959),\n",
              " ('excel', 0.888027012348175),\n",
              " ('buen', 0.8877347707748413)]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"sentiment\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMrkGM4yDdIH",
        "outputId": "4310b9a2-011c-42e2-e97f-f6705af5f76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1    3220\n",
            "-1    3220\n",
            " 0    3220\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_words = embedding_matrix.shape[0] #4016\n",
        "maxlen = 100 \n",
        "batch_size = 32\n",
        "nb_classes = 3\n",
        "nb_epoch = 3\n",
        "\n",
        "\n",
        "# Vectorize X_train and X_test to 2D tensor\n",
        "tokenizer = Tokenizer(nb_words=top_words) #only consider top 20000 words in the corpse\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "# tokenizer.word_index #access word-to-index dictionary of trained tokenizer\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_seq = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
        "X_test_seq = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
        "\n",
        "\n",
        "# one-hot encoding of y_train and y_test\n",
        "y_train_seq = np_utils.to_categorical(y_train, nb_classes)\n",
        "y_test_seq = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "print('X_train shape:', X_train_seq.shape) #(27799, 100)\n",
        "print('X_test shape:', X_test_seq.shape) #(3089, 100)\n",
        "print('y_train shape:', y_train_seq.shape) #(27799, 2)\n",
        "print('y_test shape:', y_test_seq.shape) #(3089, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlwCTkEI7DsF",
        "outputId": "07dfefb5-48ae-40b0-f02d-f4b89fd02a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (8694, 100)\n",
            "X_test shape: (966, 100)\n",
            "y_train shape: (8694, 3)\n",
            "y_test shape: (966, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "import pickle\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Construct Word2Vec embedding layer\n",
        "embedding_layer = Embedding(embedding_matrix.shape[0], #4016\n",
        "                            embedding_matrix.shape[1], #300\n",
        "                            weights=[embedding_matrix])\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(embedding_layer)\n",
        "model1.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
        "model1.add(layers.Dense(3,activation='softmax'))\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LL-JtMWP8MF",
        "outputId": "3766b91f-b111-4d4b-d08f-d60b3d483680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, None, 300)         1585500   \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 40)               51360     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 123       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,636,983\n",
            "Trainable params: 1,636,983\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model1.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history1= model1.fit(X_train_seq, y_train_seq,validation_data=(X_test_seq, y_test_seq), epochs=70, callbacks=[checkpoint1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqI4nn-VQS6e",
        "outputId": "94915ef1-0162-4754-b69b-23050bc9d9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.5327 - accuracy: 0.5652\n",
            "Epoch 1: val_accuracy improved from -inf to 0.68219, saving model to best_model1.hdf5\n",
            "272/272 [==============================] - 7s 14ms/step - loss: 0.5317 - accuracy: 0.5671 - val_loss: 0.4580 - val_accuracy: 0.6822\n",
            "Epoch 2/70\n",
            "269/272 [============================>.] - ETA: 0s - loss: 0.4051 - accuracy: 0.7276\n",
            "Epoch 2: val_accuracy did not improve from 0.68219\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.4062 - accuracy: 0.7259 - val_loss: 0.4544 - val_accuracy: 0.6304\n",
            "Epoch 3/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.7517\n",
            "Epoch 3: val_accuracy improved from 0.68219 to 0.70083, saving model to best_model1.hdf5\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3779 - accuracy: 0.7520 - val_loss: 0.4389 - val_accuracy: 0.7008\n",
            "Epoch 4/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.3116 - accuracy: 0.8112\n",
            "Epoch 4: val_accuracy did not improve from 0.70083\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3108 - accuracy: 0.8116 - val_loss: 0.4463 - val_accuracy: 0.6988\n",
            "Epoch 5/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.2524 - accuracy: 0.8593\n",
            "Epoch 5: val_accuracy improved from 0.70083 to 0.70807, saving model to best_model1.hdf5\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2527 - accuracy: 0.8590 - val_loss: 0.4440 - val_accuracy: 0.7081\n",
            "Epoch 6/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.8909\n",
            "Epoch 6: val_accuracy improved from 0.70807 to 0.73499, saving model to best_model1.hdf5\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.2046 - accuracy: 0.8908 - val_loss: 0.4590 - val_accuracy: 0.7350\n",
            "Epoch 7/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.1670 - accuracy: 0.9120\n",
            "Epoch 7: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.1670 - accuracy: 0.9120 - val_loss: 0.5247 - val_accuracy: 0.7319\n",
            "Epoch 8/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.1346 - accuracy: 0.9337\n",
            "Epoch 8: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.1347 - accuracy: 0.9337 - val_loss: 0.5488 - val_accuracy: 0.7319\n",
            "Epoch 9/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.9438\n",
            "Epoch 9: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.1186 - accuracy: 0.9438 - val_loss: 0.5771 - val_accuracy: 0.7174\n",
            "Epoch 10/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.1006 - accuracy: 0.9537\n",
            "Epoch 10: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.1003 - accuracy: 0.9541 - val_loss: 0.6102 - val_accuracy: 0.7308\n",
            "Epoch 11/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9612\n",
            "Epoch 11: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0871 - accuracy: 0.9612 - val_loss: 0.6257 - val_accuracy: 0.7350\n",
            "Epoch 12/70\n",
            "267/272 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9671\n",
            "Epoch 12: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0758 - accuracy: 0.9670 - val_loss: 0.6698 - val_accuracy: 0.7246\n",
            "Epoch 13/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9705\n",
            "Epoch 13: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.0651 - accuracy: 0.9706 - val_loss: 0.7216 - val_accuracy: 0.7174\n",
            "Epoch 14/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9718\n",
            "Epoch 14: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0610 - accuracy: 0.9718 - val_loss: 0.7170 - val_accuracy: 0.7340\n",
            "Epoch 15/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 0.9757\n",
            "Epoch 15: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0535 - accuracy: 0.9756 - val_loss: 0.7533 - val_accuracy: 0.7277\n",
            "Epoch 16/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9806\n",
            "Epoch 16: val_accuracy did not improve from 0.73499\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0453 - accuracy: 0.9806 - val_loss: 0.7863 - val_accuracy: 0.7236\n",
            "Epoch 17/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9809\n",
            "Epoch 17: val_accuracy improved from 0.73499 to 0.74224, saving model to best_model1.hdf5\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0437 - accuracy: 0.9809 - val_loss: 0.8016 - val_accuracy: 0.7422\n",
            "Epoch 18/70\n",
            "267/272 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9862\n",
            "Epoch 18: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0351 - accuracy: 0.9859 - val_loss: 0.8581 - val_accuracy: 0.7277\n",
            "Epoch 19/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9854\n",
            "Epoch 19: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0349 - accuracy: 0.9854 - val_loss: 0.8771 - val_accuracy: 0.7319\n",
            "Epoch 20/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9868\n",
            "Epoch 20: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0328 - accuracy: 0.9867 - val_loss: 0.8952 - val_accuracy: 0.7164\n",
            "Epoch 21/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9846\n",
            "Epoch 21: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0366 - accuracy: 0.9847 - val_loss: 0.8859 - val_accuracy: 0.7226\n",
            "Epoch 22/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9883\n",
            "Epoch 22: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.0276 - accuracy: 0.9883 - val_loss: 0.9093 - val_accuracy: 0.7277\n",
            "Epoch 23/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9884\n",
            "Epoch 23: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 13ms/step - loss: 0.0278 - accuracy: 0.9884 - val_loss: 0.8985 - val_accuracy: 0.7267\n",
            "Epoch 24/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9894\n",
            "Epoch 24: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0235 - accuracy: 0.9894 - val_loss: 1.0608 - val_accuracy: 0.7112\n",
            "Epoch 25/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9907\n",
            "Epoch 25: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0218 - accuracy: 0.9906 - val_loss: 1.0066 - val_accuracy: 0.7267\n",
            "Epoch 26/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9910\n",
            "Epoch 26: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.0209 - accuracy: 0.9911 - val_loss: 0.9950 - val_accuracy: 0.7360\n",
            "Epoch 27/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9911\n",
            "Epoch 27: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0194 - accuracy: 0.9911 - val_loss: 0.9860 - val_accuracy: 0.7350\n",
            "Epoch 28/70\n",
            "269/272 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9938\n",
            "Epoch 28: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0151 - accuracy: 0.9939 - val_loss: 1.0510 - val_accuracy: 0.7391\n",
            "Epoch 29/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9938\n",
            "Epoch 29: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 1.0260 - val_accuracy: 0.7329\n",
            "Epoch 30/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9918\n",
            "Epoch 30: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0187 - accuracy: 0.9917 - val_loss: 1.0981 - val_accuracy: 0.7298\n",
            "Epoch 31/70\n",
            "269/272 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9937\n",
            "Epoch 31: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0147 - accuracy: 0.9938 - val_loss: 1.0863 - val_accuracy: 0.7277\n",
            "Epoch 32/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9939\n",
            "Epoch 32: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0140 - accuracy: 0.9938 - val_loss: 1.0254 - val_accuracy: 0.7246\n",
            "Epoch 33/70\n",
            "269/272 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9936\n",
            "Epoch 33: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0138 - accuracy: 0.9936 - val_loss: 1.1262 - val_accuracy: 0.7288\n",
            "Epoch 34/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9957\n",
            "Epoch 34: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 1.1633 - val_accuracy: 0.7319\n",
            "Epoch 35/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9939\n",
            "Epoch 35: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 1.0928 - val_accuracy: 0.7277\n",
            "Epoch 36/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9938\n",
            "Epoch 36: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0130 - accuracy: 0.9938 - val_loss: 1.1276 - val_accuracy: 0.7246\n",
            "Epoch 37/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9954\n",
            "Epoch 37: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 1.1790 - val_accuracy: 0.7246\n",
            "Epoch 38/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9950\n",
            "Epoch 38: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 1.1625 - val_accuracy: 0.7257\n",
            "Epoch 39/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9957\n",
            "Epoch 39: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 1.1666 - val_accuracy: 0.7329\n",
            "Epoch 40/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9956\n",
            "Epoch 40: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0101 - accuracy: 0.9956 - val_loss: 1.2737 - val_accuracy: 0.7153\n",
            "Epoch 41/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9944\n",
            "Epoch 41: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0106 - accuracy: 0.9945 - val_loss: 1.1540 - val_accuracy: 0.7298\n",
            "Epoch 42/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9956\n",
            "Epoch 42: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0086 - accuracy: 0.9956 - val_loss: 1.1874 - val_accuracy: 0.7340\n",
            "Epoch 43/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9970\n",
            "Epoch 43: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 1.2222 - val_accuracy: 0.7340\n",
            "Epoch 44/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9958\n",
            "Epoch 44: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 1.1963 - val_accuracy: 0.7143\n",
            "Epoch 45/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9971\n",
            "Epoch 45: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0075 - accuracy: 0.9971 - val_loss: 1.2395 - val_accuracy: 0.7215\n",
            "Epoch 46/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9965\n",
            "Epoch 46: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0075 - accuracy: 0.9965 - val_loss: 1.3111 - val_accuracy: 0.7288\n",
            "Epoch 47/70\n",
            "269/272 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9978\n",
            "Epoch 47: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 1.3280 - val_accuracy: 0.7257\n",
            "Epoch 48/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9958\n",
            "Epoch 48: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0093 - accuracy: 0.9959 - val_loss: 1.3084 - val_accuracy: 0.7319\n",
            "Epoch 49/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9957\n",
            "Epoch 49: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0096 - accuracy: 0.9956 - val_loss: 1.2452 - val_accuracy: 0.7308\n",
            "Epoch 50/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9965\n",
            "Epoch 50: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0074 - accuracy: 0.9965 - val_loss: 1.3198 - val_accuracy: 0.7246\n",
            "Epoch 51/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9964\n",
            "Epoch 51: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 1.3032 - val_accuracy: 0.7319\n",
            "Epoch 52/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9965\n",
            "Epoch 52: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0072 - accuracy: 0.9965 - val_loss: 1.3631 - val_accuracy: 0.7360\n",
            "Epoch 53/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9967\n",
            "Epoch 53: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0059 - accuracy: 0.9968 - val_loss: 1.3218 - val_accuracy: 0.7153\n",
            "Epoch 54/70\n",
            "269/272 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9976\n",
            "Epoch 54: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 1.3526 - val_accuracy: 0.7288\n",
            "Epoch 55/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9955\n",
            "Epoch 55: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0091 - accuracy: 0.9955 - val_loss: 1.3369 - val_accuracy: 0.7153\n",
            "Epoch 56/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9964\n",
            "Epoch 56: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0067 - accuracy: 0.9964 - val_loss: 1.3310 - val_accuracy: 0.7288\n",
            "Epoch 57/70\n",
            "267/272 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9973\n",
            "Epoch 57: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 1.2993 - val_accuracy: 0.7246\n",
            "Epoch 58/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9975\n",
            "Epoch 58: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 1.3210 - val_accuracy: 0.7257\n",
            "Epoch 59/70\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9972\n",
            "Epoch 59: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 1.3638 - val_accuracy: 0.7205\n",
            "Epoch 60/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9984\n",
            "Epoch 60: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 1.3487 - val_accuracy: 0.7308\n",
            "Epoch 61/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9975\n",
            "Epoch 61: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0052 - accuracy: 0.9975 - val_loss: 1.3138 - val_accuracy: 0.7246\n",
            "Epoch 62/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9984\n",
            "Epoch 62: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 1.3470 - val_accuracy: 0.7236\n",
            "Epoch 63/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9972\n",
            "Epoch 63: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 1.3401 - val_accuracy: 0.7184\n",
            "Epoch 64/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9977\n",
            "Epoch 64: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 1.3525 - val_accuracy: 0.7215\n",
            "Epoch 65/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9984\n",
            "Epoch 65: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 1.4056 - val_accuracy: 0.7215\n",
            "Epoch 66/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9978\n",
            "Epoch 66: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0045 - accuracy: 0.9978 - val_loss: 1.3949 - val_accuracy: 0.7133\n",
            "Epoch 67/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9976\n",
            "Epoch 67: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 1.3763 - val_accuracy: 0.7133\n",
            "Epoch 68/70\n",
            "268/272 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986\n",
            "Epoch 68: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 1.4180 - val_accuracy: 0.7236\n",
            "Epoch 69/70\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9987\n",
            "Epoch 69: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 1.4113 - val_accuracy: 0.7277\n",
            "Epoch 70/70\n",
            "272/272 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9974\n",
            "Epoch 70: val_accuracy did not improve from 0.74224\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0043 - accuracy: 0.9974 - val_loss: 1.5154 - val_accuracy: 0.7195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluar al modelo"
      ],
      "metadata": {
        "id": "8QKI51EmbRxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model(\"best_model1.hdf5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "X-7Ky2ECbOF3",
        "outputId": "4aeab32a-d693-4883-bc93-732d2557de4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-5f83ebb8324f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_model1.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)\n",
        "\n",
        "print(history.history.keys())\n",
        "# history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T5vWuqxPbWYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "predictions = best_model.predict(X_test)\n",
        "start_time = time.time()\n",
        "test_predictions = np.argmax(best_model.predict(X_test), axis=-1)\n",
        "print(classification_report(y_test.argmax(axis=1),test_predictions))\n",
        "print(\"Time taken to predict the model \" + str(time.time() - start_time))"
      ],
      "metadata": {
        "id": "lWRvuKdQbbI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))\n",
        "\n",
        "import seaborn as sns\n",
        "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
        "#Normalizing\n",
        "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})"
      ],
      "metadata": {
        "id": "PpusbRVYbcvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct Word2Vec embedding layer\n",
        "embedding_layer = Embedding(embedding_matrix.shape[0], #4016\n",
        "                            embedding_matrix.shape[1], #300\n",
        "                            weights=[embedding_matrix])\n",
        "\n",
        "\n",
        "# Construct LSTM with Word2Vec embedding\n",
        "model2 = Sequential()\n",
        "model2.add(embedding_layer)\n",
        "model2.add(LSTM(128, recurrent_dropout =0.2)) \n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(nb_classes))\n",
        "model2.add(Activation('softmax'))\n",
        "model2.summary()\n",
        "\n",
        "# Compile model\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_train_seq, y_train_seq, batch_size=batch_size, epochs=70, verbose=1)\n",
        "\n",
        "\n",
        "# Model evaluation\n",
        "score = model2.evaluate(X_test_seq, y_test_seq, batch_size=batch_size)\n",
        "print('Test loss : {:.4f}'.format(score[0]))\n",
        "print('Test accuracy : {:.4f}'.format(score[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "XmACoO8X7Dkl",
        "outputId": "6f0786aa-2086-458f-a2d7-2df907940ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 300)         1541100   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               219648    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 387       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,761,135\n",
            "Trainable params: 1,761,135\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "272/272 [==============================] - 100s 348ms/step - loss: 0.5140 - accuracy: 0.5874\n",
            "Epoch 2/3\n",
            " 28/272 [==>...........................] - ETA: 1:38 - loss: 0.4162 - accuracy: 0.7143"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-271097467204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model2.predict(X_test_seq) \n",
        "pred = np.argmax(pred, axis = 1)[:5] \n",
        "label = np.argmax(y_test_seq,axis = 1)[:5] \n",
        "\n",
        "print(pred) \n",
        "print(label)"
      ],
      "metadata": {
        "id": "0BShFz597DWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = ['Negative','Neutral','Positive']\n",
        "sequence = tokenizer.texts_to_sequences(['mal curso'])\n",
        "print(sequence)\n",
        "#test = sequence.pad_sequences(sequence, maxlen=100)\n",
        "sentiment[np.around(model2.predict(sequence), decimals=0).argmax(axis=1)[0]]\n",
        "print(np.around(model2.predict(sequence), decimals=0).argmax(axis=1)[0])\n",
        "print(sentiment[np.around(model2.predict(sequence), decimals=0).argmax(axis=1)[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_AxP7rG7HN2",
        "outputId": "4cfb079c-971a-40bc-eee6-1430fc07c7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[472, 30]]\n",
            "2\n",
            "Positive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "TEST1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}